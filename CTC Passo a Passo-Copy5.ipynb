{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  Compatibility imports\n",
    "from scipy.io import wavfile\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "import scipy.io.wavfile as wav\n",
    "import numpy as np\n",
    "\n",
    "from six.moves import xrange as range\n",
    "\n",
    "try:\n",
    "    from tensorflow.python.ops import ctc_ops\n",
    "except ImportError:\n",
    "    from tensorflow.contrib.ctc import ctc_ops\n",
    "\n",
    "try:\n",
    "    from python_speech_features import mfcc\n",
    "except ImportError:\n",
    "    print(\"Failed to import python_speech_features.\\n Try pip install python_speech_features.\")\n",
    "    raise ImportError\n",
    "\n",
    "from utils import maybe_download as maybe_download\n",
    "from utils import sparse_tuple_from as sparse_tuple_from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import scipy.io.wavfile as wav\n",
    "from unicodedata import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remover_acentos(txt):\n",
    "    return normalize('NFKD', txt).encode('ASCII','ignore').decode('ASCII')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Constants\n",
    "SPACE_TOKEN = '<space>'\n",
    "SPACE_INDEX = 0\n",
    "FIRST_INDEX = ord('a') - 1  # 0 is reserved to space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Some configs\n",
    "num_features = 13\n",
    "# Accounting the 0th indice +  space + blank label = 28 characters\n",
    "num_classes = ord('z') - ord('a') + 1 + 1 + 1\n",
    "\n",
    "# Hyper-parameters\n",
    "num_epochs = 50\n",
    "num_hidden = 50\n",
    "num_layers = 1\n",
    "batch_size = 1\n",
    "initial_learning_rate = 1e-2\n",
    "momentum = 0.9\n",
    "\n",
    "num_examples = 1\n",
    "num_batches_per_epoch = int(num_examples/batch_size)\n",
    "num_arquivos = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def audioTexto(qtde):\n",
    "    arquivos_e_diretorios = os.listdir('data/') #lista de arquivos e diretórios\n",
    "    diretorios = []\n",
    "    #pega somente os diretórios e coloca na lista de diretorios\n",
    "    for arquivo in arquivos_e_diretorios:\n",
    "            if arquivo.find('.tgz') == -1:\n",
    "                diretorios.append(arquivo)   \n",
    "    \n",
    "    #pega somente os arquivos wav e coloca na lista de waves\n",
    "    waves = []    \n",
    "    for diretorio in diretorios:\n",
    "        for file in glob.glob('data/' + diretorio+'/wav/*.wav'):\n",
    "            waves.append(file)\n",
    "    lista_audio = []\n",
    "    lista_texto = []\n",
    "    lista_waves = []\n",
    "    lista_audio_texto = lista_audio, lista_texto    \n",
    "    for w in waves[:qtde]:\n",
    "        txt = w[:-11]+'etc/prompts-original' #pega o nome e retira os últimos 11 digitos e completa do /etc até o txt\n",
    "        numero = w[-7:-4]  #pega somente o número do arquivo de áudio\n",
    "        try:\n",
    "            for line in open(txt):\n",
    "                if(line.strip().startswith(numero)): #pega o texto a partir do número do audio                    \n",
    "                    lista_audio.append(w)\n",
    "                    _, arq_audio = wav.read(w)\n",
    "                    lista_waves.append(arq_audio)\n",
    "                    lista_texto.append(remover_acentos(line[4:-1]).lower().replace('.','').replace('?',''))                   \n",
    "        except IOError as e:\n",
    "            print(\"Não encontrou o arquivo:\" + w)  \n",
    "    return lista_audio, lista_texto, lista_waves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = audioTexto(num_arquivos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path, texto, audio = t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "audio = np.concatenate(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fs = 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "audio.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pylab import*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "timeArray = arange(0, len(audio), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot(timeArray, audio, color='r')\n",
    "ylabel('Amplitude')\n",
    "xlabel('Time (ms)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inputs = mfcc(audio, samplerate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tranform in 3D array\n",
    "train_inputs = np.asarray(inputs[np.newaxis, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_inputs = (train_inputs - np.mean(train_inputs))/np.std(train_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_seq_len = [train_inputs.shape[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#original = ' '.join(s.strip().lower().split(' ')[2:]).replace('.', '')\n",
    "#original = 'Aquela mulher e portuguesa'.lower()\n",
    "#original = 'Aquela mulher e portuguesa Vou cumprir'.lower()\n",
    "#original = 'Aquela mulher e portuguesa Vou cumprir Vamos comprar um carro que funciona Os funcionarios chegam tarde todos os dias'.lower()\n",
    "original = ''.join(texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "targets = original.replace(' ', '  ')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "targets = targets.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Adding blank label\n",
    "targets = np.hstack([SPACE_TOKEN if x == '' else list(x) for x in targets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Transform char into index\n",
    "targets = np.asarray([SPACE_INDEX if x == SPACE_TOKEN else ord(x) - FIRST_INDEX\n",
    "                      for x in targets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating sparse representation to feed the placeholder\n",
    "train_targets = sparse_tuple_from([targets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We don't have a validation dataset :(\n",
    "val_inputs, val_targets, val_seq_len = train_inputs, train_targets, train_seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# THE MAIN CODE!\n",
    "\n",
    "graph = tf.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# THE MAIN CODE!\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    # e.g: log filter bank or MFCC features\n",
    "    # Has size [batch_size, max_stepsize, num_features], but the\n",
    "    # batch_size and max_stepsize can vary along each step\n",
    "    inputs = tf.placeholder(tf.float32, [None, None, num_features])\n",
    "\n",
    "    # Here we use sparse_placeholder that will generate a\n",
    "    # SparseTensor required by ctc_loss op.\n",
    "    targets = tf.sparse_placeholder(tf.int32)\n",
    "\n",
    "    # 1d array of size [batch_size]\n",
    "    seq_len = tf.placeholder(tf.int32, [None])\n",
    "\n",
    "    # Defining the cell\n",
    "    # Can be:\n",
    "    #   tf.nn.rnn_cell.RNNCell\n",
    "    #   tf.nn.rnn_cell.GRUCell\n",
    "    cell = tf.nn.rnn_cell.LSTMCell(num_hidden, state_is_tuple=True)\n",
    "\n",
    "    # Stacking rnn cells\n",
    "    stack = tf.nn.rnn_cell.MultiRNNCell([cell] * num_layers,\n",
    "                                        state_is_tuple=True)\n",
    "\n",
    "    # The second output is the last state and we will no use that\n",
    "    outputs, _ = tf.nn.dynamic_rnn(stack, inputs, seq_len, dtype=tf.float32)\n",
    "\n",
    "    shape = tf.shape(inputs)\n",
    "    batch_s, max_timesteps = shape[0], shape[1]\n",
    "\n",
    "    # Reshaping to apply the same weights over the timesteps\n",
    "    outputs = tf.reshape(outputs, [-1, num_hidden])\n",
    "\n",
    "    # Truncated normal with mean 0 and stdev=0.1\n",
    "    # Tip: Try another initialization\n",
    "    # see https://www.tensorflow.org/versions/r0.9/api_docs/python/contrib.layers.html#initializers\n",
    "    W = tf.Variable(tf.truncated_normal([num_hidden,\n",
    "                                         num_classes],\n",
    "                                        stddev=0.1))\n",
    "    # Zero initialization\n",
    "    # Tip: Is tf.zeros_initializer the same?\n",
    "    b = tf.Variable(tf.constant(0., shape=[num_classes]))\n",
    "\n",
    "    # Doing the affine projection\n",
    "    logits = tf.matmul(outputs, W) + b\n",
    "\n",
    "    # Reshaping back to the original shape\n",
    "    logits = tf.reshape(logits, [batch_s, -1, num_classes])\n",
    "\n",
    "    # Time major\n",
    "    logits = tf.transpose(logits, (1, 0, 2))\n",
    "\n",
    "    loss = ctc_ops.ctc_loss(logits, targets, seq_len)\n",
    "    cost = tf.reduce_mean(loss)\n",
    "\n",
    "    optimizer = tf.train.MomentumOptimizer(initial_learning_rate,\n",
    "                                           0.9).minimize(cost)\n",
    "\n",
    "    # Option 2: tf.contrib.ctc.ctc_beam_search_decoder\n",
    "    # (it's slower but you'll get better results)\n",
    "    decoded, log_prob = ctc_ops.ctc_greedy_decoder(logits, seq_len)\n",
    "\n",
    "    # Inaccuracy: label error rate\n",
    "    ler = tf.reduce_mean(tf.edit_distance(tf.cast(decoded[0], tf.int32),\n",
    "                                          targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.Session(graph=graph) as session:\n",
    "    # Initializate the weights and biases\n",
    "    tf.initialize_all_variables().run()\n",
    "\n",
    "\n",
    "    for curr_epoch in range(num_epochs):\n",
    "        train_cost = train_ler = 0\n",
    "        start = time.time()\n",
    "\n",
    "        for batch in range(num_batches_per_epoch):\n",
    "\n",
    "            feed = {inputs: train_inputs,\n",
    "                    targets: train_targets,\n",
    "                    seq_len: train_seq_len}\n",
    "\n",
    "            batch_cost, _ = session.run([cost, optimizer], feed)\n",
    "            train_cost += batch_cost*batch_size\n",
    "            train_ler += session.run(ler, feed_dict=feed)*batch_size\n",
    "\n",
    "        train_cost /= num_examples\n",
    "        train_ler /= num_examples\n",
    "\n",
    "        val_feed = {inputs: val_inputs,\n",
    "                    targets: val_targets,\n",
    "                    seq_len: val_seq_len}\n",
    "\n",
    "        val_cost, val_ler = session.run([cost, ler], feed_dict=val_feed)\n",
    "\n",
    "        log = \"Epoch {}/{}, train_cost = {:.3f}, train_ler = {:.3f}, val_cost = {:.3f}, val_ler = {:.3f}, time = {:.3f}\"\n",
    "        print(log.format(curr_epoch+1, num_epochs, train_cost, train_ler,\n",
    "                         val_cost, val_ler, time.time() - start))\n",
    "    # Decoding\n",
    "    d = session.run(decoded[0], feed_dict=feed)\n",
    "    str_decoded = ''.join([chr(x) for x in np.asarray(d[1]) + FIRST_INDEX])\n",
    "    # Replacing blank label to none\n",
    "    str_decoded = str_decoded.replace(chr(ord('z') + 1), '')\n",
    "    # Replacing space label to space\n",
    "    str_decoded = str_decoded.replace(chr(ord('a') - 1), ' ')\n",
    "\n",
    "    print('Original:\\n%s' % original)\n",
    "    print('Decoded:\\n%s' % str_decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
